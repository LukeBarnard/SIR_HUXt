{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ErfaWarning: ERFA function \"dtf2d\" yielded 1 of \"dubious year (Note 6)\" [astropy._erfa.core]\n",
      "WARNING: ErfaWarning: ERFA function \"d2dtf\" yielded 1 of \"dubious year (Note 5)\" [astropy._erfa.core]\n"
     ]
    }
   ],
   "source": [
    "from astropy.time import Time, TimeDelta\n",
    "import astropy.units as u\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import moviepy.editor as mpy\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sunpy.coordinates.sun as sn\n",
    "import scipy.ndimage as ndi\n",
    "import scipy.stats as st\n",
    "# Our own library for using spice with STEREO (https://github.com/LukeBarnard/stereo_spice)\n",
    "from stereo_spice.coordinates import StereoSpice\n",
    "# Local packages\n",
    "import HUXt as H\n",
    "\n",
    "spice = StereoSpice()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_huxt(start_time, uniform_wind=True):\n",
    "    \"\"\"\n",
    "    Initialise HUXt with some predetermined boundary/initial conditions\n",
    "    start_time should be astropy.Time object.\n",
    "    wind should be uniform or structured\n",
    "    \"\"\"\n",
    "    cr_num = np.fix(sn.carrington_rotation_number(start_time))\n",
    "    ert = H.Observer('EARTH', start_time)\n",
    "\n",
    "    # Set up HUXt for a 5 day simulation with homogenous inner boundary.\n",
    "    vr_in, br_in = H.Hin.get_MAS_long_profile(cr_num, ert.lat.to(u.deg))\n",
    "    if uniform_wind:\n",
    "        vr_in = np.zeros(vr_in.shape) + 400*vr_in.unit\n",
    "        \n",
    "    model = H.HUXt(v_boundary=vr_in, cr_num=cr_num, cr_lon_init=ert.lon_c, latitude=ert.lat.to(u.deg),\n",
    "                   br_boundary=br_in, lon_start=270*u.deg, lon_stop=90*u.deg, simtime=3.5*u.day, dt_scale=4)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_base_cme(v=1000, lon=0, lat=0, width=45, thickness=5):\n",
    "    \"\"\"\n",
    "    Return the base CME, which is used to establish the pseudo-truth CME and the SIR ensemble\n",
    "    \"\"\"\n",
    "    t_launch = (1*u.hr).to(u.s)\n",
    "    cme = H.ConeCME(t_launch=t_launch, longitude=lon*u.deg, latitude=lat*u.deg, width=width*u.deg, v=v*(u.km/u.s), thickness=thickness*u.solRad)\n",
    "    return cme\n",
    "\n",
    "def perturb_cone_cme(cme):\n",
    "    \"\"\"\n",
    "    Perturb a ConeCME's parameters. Used to establish the pseudo-truth CME and the initial SIR ensemble members. \n",
    "    \"\"\"\n",
    "    lon_spread = 10*u.deg\n",
    "    lat_spread = 10*u.deg\n",
    "    width_spread = 10*u.deg\n",
    "    v_spread = 100*(u.km/u.s)\n",
    "    thickness_spread = 1*u.solRad\n",
    "    \n",
    "    randoms = np.random.uniform(-1,1,5)\n",
    "    lon_new = cme.longitude + randoms[0]*lon_spread\n",
    "    lat_new = cme.latitude + randoms[1]*lat_spread\n",
    "    width_new = cme.width + randoms[2]*width_spread\n",
    "    v_new = cme.v + randoms[3]*v_spread\n",
    "    thickness_new = cme.thickness + randoms[4]*thickness_spread\n",
    "    \n",
    "    cme_perturb = H.ConeCME(t_launch=cme.t_launch,\n",
    "                            longitude=lon_new,\n",
    "                            latitude=lat_new,\n",
    "                            width=width_new,\n",
    "                            v=v_new,\n",
    "                            thickness=thickness_new)\n",
    "    return cme_perturb\n",
    "\n",
    "\n",
    "class Observer:\n",
    "    \n",
    "    @u.quantity_input(longitude=u.deg)\n",
    "    def __init__(self, model, longitude, el_min=4.0, el_max=30.0):\n",
    "        \n",
    "        ert_ephem = model.get_observer('EARTH')\n",
    "        \n",
    "        self.time = ert_ephem.time \n",
    "        self.r = ert_ephem.r\n",
    "        self.lon = ert_ephem.lon + longitude\n",
    "        self.lat = ert_ephem.lat\n",
    "        self.el_min = el_min\n",
    "        self.el_max = el_max\n",
    "        # Force longitude into 0-360 domain\n",
    "        id_over = self.lon > 360*u.deg\n",
    "        id_under = self.lon < 0*u.deg\n",
    "        if np.any(id_over):\n",
    "            self.lon[id_over] = self.lon[id_over] - 360*u.deg\n",
    "        if np.any(id_under):\n",
    "            self.lon[id_under] = self.lon[id_under] + 360*u.deg\n",
    "        \n",
    "        cme = model.cmes[0]\n",
    "        self.model_flank = self.compute_flank_profile(cme)\n",
    "        \n",
    "    def compute_flank_profile(self, cme):\n",
    "        \"\"\"\n",
    "        Compute the time elongation profile of the flank of a ConeCME in HUXt. The observer longtidue is specified relative to Earth,\n",
    "        and but otherwise matches Earth's coords. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observer_lon: Angular separation of Earth and the observer, in HEEQ.\n",
    "        cme: A ConeCME object from a completed HUXt run (i.e the ConeCME.coords dictionary has been populated).\n",
    "        Returns\n",
    "        -------\n",
    "        obs_profile: Pandas dataframe giving the coordinates of the ConeCME flank from STA's perspective, including the\n",
    "                    time, elongation, position angle, and HEEQ radius and longitude.\n",
    "        \"\"\"\n",
    "        times = Time([coord['time'] for i, coord in cme.coords.items()])\n",
    "\n",
    "        # Compute observers location using earth ephem, adding on observers longitude offset from Earth and correct for runover 2*pi\n",
    "        flank = pd.DataFrame(index=np.arange(times.size), columns=['time', 'el', 'r', 'lon'])\n",
    "        flank['time'] = times.jd\n",
    "\n",
    "        for i, coord in cme.coords.items():\n",
    "\n",
    "            if len(coord['r']) == 0:\n",
    "                flank.loc[i, ['lon','r', 'el']] = np.NaN\n",
    "                continue\n",
    "\n",
    "            r_obs = self.r[i]\n",
    "            x_obs = self.r[i] * np.cos(self.lat[i]) * np.cos(self.lon[i])\n",
    "            y_obs = self.r[i] * np.cos(self.lat[i]) * np.sin(self.lon[i])\n",
    "            z_obs = self.r[i] * np.sin(self.lat[i])\n",
    "\n",
    "            lon_cme = coord['lon']\n",
    "            lat_cme = coord['lat']\n",
    "            r_cme = coord['r']\n",
    "\n",
    "            x_cme = r_cme * np.cos(lat_cme) * np.cos(lon_cme)\n",
    "            y_cme = r_cme * np.cos(lat_cme) * np.sin(lon_cme)\n",
    "            z_cme = r_cme * np.sin(lat_cme)\n",
    "            #############\n",
    "            # Compute the observer CME distance, S, and elongation\n",
    "\n",
    "            x_cme_s = x_cme - x_obs\n",
    "            y_cme_s = y_cme - y_obs\n",
    "            z_cme_s = z_cme - z_obs\n",
    "            s = np.sqrt(x_cme_s**2 + y_cme_s**2 + z_cme_s**2)\n",
    "\n",
    "            numer = (r_obs**2 + s**2 - r_cme**2).value\n",
    "            denom = (2.0 * r_obs * s).value\n",
    "            e_obs = np.arccos(numer / denom)\n",
    "\n",
    "            # Find the flank coordinate and update output\n",
    "            id_obs_flank = np.argmax(e_obs)       \n",
    "            flank.loc[i, 'lon'] = lon_cme[id_obs_flank].value\n",
    "            flank.loc[i, 'r'] = r_cme[id_obs_flank].value\n",
    "            flank.loc[i, 'el'] = np.rad2deg(e_obs[id_obs_flank])\n",
    "\n",
    "        # Force values to be floats.\n",
    "        keys = ['lon', 'r', 'el']\n",
    "        flank[keys] = flank[keys].astype(np.float64)\n",
    "        return flank\n",
    "    \n",
    "    def compute_synthetic_obs(self, el_spread=0.5, cadence=5, el_min=4.0, el_max=30.0):\n",
    "        \"\"\"\n",
    "        Return synthetic observations with a specified uncertainty spread, cadence, and maximum elongation.\n",
    "        el_spread = standard deviation of random gaussian noise added to the modelled elongation.\n",
    "        cadence = The cadence with witch observations are returned, as a whole number of model time steps.\n",
    "        el_min = The minimum elongation of the observers field of view.\n",
    "        el_max = The maximum elongation of the observers field of view.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute the time-elongation profiles of the CME flanks from STA and STB\n",
    "        model_flank = self.model_flank.copy()\n",
    "\n",
    "        # Remove invalid points\n",
    "        model_flank.dropna(inplace=True)\n",
    "\n",
    "        # Add observation noise.\n",
    "        obs_flank = model_flank.loc[:, ['time', 'el']].copy()\n",
    "        obs_flank['el'] = obs_flank['el'] + el_spread*np.random.randn(obs_flank.shape[0])\n",
    "\n",
    "        # Only keep every dt_scale'th observation and reindex - dt_scale=5 corrsponds to ~2hr\n",
    "        obs_flank = obs_flank[::cadence]\n",
    "        obs_flank.set_index(np.arange(0, obs_flank.shape[0]), inplace=True)\n",
    "\n",
    "        # Only return up to el_max ~ (approx HI1 FOV is 25deg)\n",
    "        id_fov = (obs_flank['el'] >= el_min) & (obs_flank['el'] <= el_max)\n",
    "        obs_flank = obs_flank[id_fov]\n",
    "        return obs_flank\n",
    "\n",
    "def compute_observation_likelihood(t_obs, e_obs, profile):\n",
    "    \"\"\"\n",
    "    Compute the likelihood of an observed elongation measurement for a modelled elongation measurement.\n",
    "    Assumes a gaussian likelihood centered on the modelled elongation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the modelled elon at observation time\n",
    "    e_mod = profile.loc[profile['time'] == t_obs, 'el'].values[0]\n",
    "    # Compute likelihood of the observation.\n",
    "    if np.isnan(e_mod):\n",
    "        lkhd = np.NaN\n",
    "    else:\n",
    "        lkhd = st.norm.pdf(e_obs, loc=e_mod, scale=0.5)\n",
    "        \n",
    "    return lkhd\n",
    "\n",
    "def get_cme_params_for_sir(cme):\n",
    "    \"\"\"\n",
    "    Form an array of the CME parameter values that are kept track of in the ensemble members.\n",
    "    \"\"\"\n",
    "    params = np.array([cme.t_launch.to('s').value, cme.longitude.to('rad').value, cme.latitude.to('rad').value,\n",
    "                          cme.width.to('rad').value, cme.v.value, cme.thickness.to('km').value])\n",
    "    \n",
    "    return params\n",
    "\n",
    "def create_analysis_output_file(filename):\n",
    "    \"\"\"\n",
    "    Create a HDF5 file for storing the SIR analysis steps.\n",
    "    \"\"\"\n",
    "    proj_dirs = H._setup_dirs_()\n",
    "    out_filepath = os.path.join(proj_dirs['out_data'], filename)\n",
    "    if os.path.isfile(out_filepath):\n",
    "        # File exists, so delete and start new.\n",
    "        print(\"Warning: {} already exists. Overwriting\".format(out_filepath))\n",
    "        os.remove(out_filepath)\n",
    "\n",
    "    out_file = h5py.File(out_filepath, 'w')\n",
    "    return out_file\n",
    "\n",
    "def cme_kde_resample_with_weights(cme_prior, weights):\n",
    "    \"\"\"\n",
    "    Use kernel density estimation to resample particles from the prior distriubtion given the particle weights.\n",
    "    \"\"\"\n",
    "    # Find valid weights, and pull out each corresponding particles parameters\n",
    "    n_ensemble = len(weights)\n",
    "    valid_weights = np.isfinite(weights)\n",
    "    weights = weights[valid_weights]\n",
    "    lon = cme_prior[valid_weights, 1].squeeze()\n",
    "    lat = cme_prior[valid_weights, 2].squeeze()\n",
    "    width = cme_prior[valid_weights, 3].squeeze()\n",
    "    v = cme_prior[valid_weights, 4].squeeze()\n",
    "    thick = cme_prior[valid_weights, 5].squeeze()\n",
    "    \n",
    "    # Force lon so no disconinuity at 2pi\n",
    "    lon[lon>=np.pi] += -2*np.pi\n",
    "\n",
    "    # KDE fit each distribution, draw random sample. \n",
    "    cme_update = np.zeros(cme_prior.shape)*np.NaN\n",
    "    cme_update[:, 0] = cme_prior[:, 0].copy()\n",
    "    \n",
    "    col_id = [1,2,3,4,5]\n",
    "    param = [lon, lat, width, v, thick]\n",
    "    for col, p in zip(col_id, param):\n",
    "        kde = st.gaussian_kde(p, bw_method='silverman',  weights=weights)\n",
    "        sample = kde.resample(n_ensemble)\n",
    "        cme_update[:, col] = sample.copy()\n",
    "        \n",
    "    # Put lon back on 0-2pi domain\n",
    "    id_low = cme_update[:, 1] < 0\n",
    "    cme_update[id_low, 1] += 2*np.pi\n",
    "    \n",
    "    return cme_update\n",
    "\n",
    "\n",
    "def update_ensemble_conecmes(cme_params):\n",
    "    \"\"\"\n",
    "    Produce the list of updated conecmes.\n",
    "    \"\"\"\n",
    "    conecme_update = []\n",
    "    for i in range(cme_params.shape[0]):\n",
    "        conecme = H.ConeCME(t_launch=cme_params[i, 0]*u.s,\n",
    "                            longitude=cme_params[i, 1]*u.rad,\n",
    "                            latitude=cme_params[i, 2]*u.rad,\n",
    "                            width=cme_params[i, 3]*u.rad,\n",
    "                            v=cme_params[i, 4]*(u.km/u.s),\n",
    "                            thickness=(cme_params[i, 5]*u.km).to(u.solRad))\n",
    "        conecme_update.append(conecme)\n",
    "        \n",
    "    return conecme_update\n",
    "\n",
    "\n",
    "def plot_huxt_with_observer(time, model, observer, add_flank=False, add_fov=False):\n",
    "    \n",
    "    id_t = np.argmin(np.abs(model.time_out - time))\n",
    "\n",
    "    # Get plotting data\n",
    "    lon_arr, dlon, nlon = H.longitude_grid()\n",
    "    lon, rad = np.meshgrid(lon_arr.value, model.r.value)\n",
    "    mymap = mpl.cm.viridis\n",
    "    v_sub = model.v_grid_cme.value[id_t, :, :].copy()\n",
    "    # Insert into full array\n",
    "    if lon_arr.size != model.lon.size:\n",
    "        v = np.zeros((model.nr, nlon)) * np.NaN\n",
    "        if model.lon.size != 1:\n",
    "            for i, lo in enumerate(model.lon):\n",
    "                id_match = np.argwhere(lon_arr == lo)[0][0]\n",
    "                v[:, id_match] = v_sub[:, i]\n",
    "        else:\n",
    "            print('Warning: Trying to contour single radial solution will fail.')\n",
    "    else:\n",
    "        v = v_sub\n",
    "\n",
    "    # Pad out to fill the full 2pi of contouring\n",
    "    pad = lon[:, 0].reshape((lon.shape[0], 1)) + model.twopi\n",
    "    lon = np.concatenate((lon, pad), axis=1)\n",
    "    pad = rad[:, 0].reshape((rad.shape[0], 1))\n",
    "    rad = np.concatenate((rad, pad), axis=1)\n",
    "    pad = v[:, 0].reshape((v.shape[0], 1))\n",
    "    v = np.concatenate((v, pad), axis=1)\n",
    "\n",
    "    mymap.set_over('lightgrey')\n",
    "    mymap.set_under([0, 0, 0])\n",
    "    levels = np.arange(200, 800 + 10, 10)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": \"polar\"})\n",
    "    cnt = ax.contourf(lon, rad, v, levels=levels, cmap=mymap, extend='both')\n",
    "\n",
    "    # Add on CME boundaries and Observer\n",
    "    cme = model.cmes[0]\n",
    "    ax.plot(cme.coords[id_t]['lon'], cme.coords[id_t]['r'], '-', color='darkorange', linewidth=3, zorder=3)\n",
    "    ert = model.get_observer('EARTH')\n",
    "    ax.plot(ert.lon[id_t], ert.r[id_t], 'co', markersize=16, label='Earth')            \n",
    "\n",
    "    # Add on the observer\n",
    "    ax.plot(observer.lon[id_t], observer.r[id_t], 's', color='r', markersize=16, label='Observer')\n",
    "        \n",
    "    if add_flank:\n",
    "        flank_lon = observer.model_flank.loc[id_t,'lon']\n",
    "        flank_rad = observer.model_flank.loc[id_t,'r']\n",
    "        ax.plot(flank_lon, flank_rad, 'r.', markersize=10, zorder=4)\n",
    "        # Add observer-flank line\n",
    "        ro = observer.r[id_t]\n",
    "        lo = observer.lon[id_t]\n",
    "        ax.plot([lo.value, flank_lon], [ro.value, flank_rad], 'r--', zorder=4)\n",
    "        \n",
    "    if add_fov:\n",
    "        flank_lon = observer.model_flank.loc[id_t,'lon']\n",
    "        flank_rad = observer.model_flank.loc[id_t,'r']\n",
    "        fov_patch = get_fov_patch(observer.r[id_t], observer.lon[id_t], observer.el_min, observer.el_max)\n",
    "        ax.add_patch(fov_patch)\n",
    "\n",
    "    ax.set_ylim(0, 240)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.patch.set_facecolor('slategrey')\n",
    "\n",
    "    fig.subplots_adjust(left=0.05, bottom=0.16, right=0.95, top=0.99)\n",
    "    # Add color bar\n",
    "    pos = ax.get_position()\n",
    "    dw = 0.005\n",
    "    dh = 0.045\n",
    "    left = pos.x0 + dw\n",
    "    bottom = pos.y0 - dh\n",
    "    wid = pos.width - 2 * dw\n",
    "    cbaxes = fig.add_axes([left, bottom, wid, 0.03])\n",
    "    cbar1 = fig.colorbar(cnt, cax=cbaxes, orientation='horizontal')\n",
    "    cbar1.set_label('Solar Wind speed (km/s)')\n",
    "    cbar1.set_ticks(np.arange(200, 810, 100))\n",
    "    return fig, ax\n",
    "\n",
    "def get_fov_patch(ro, lo, el_min, el_max):\n",
    "    \"\"\"\n",
    "    Function to compute a matplotlib patch to higlight an observers field of view. \n",
    "    ro = radius of observer (in solRad)\n",
    "    lo = longitude of observer (in rad)\n",
    "    el_min = minimum elongation of the field of view\n",
    "    el_max = maximum elongation of the field of view\n",
    "    \"\"\"\n",
    "    xo = ro*np.cos(lo)\n",
    "    yo = ro*np.sin(lo)\n",
    "    \n",
    "    fov_patch =[[lo.value, ro.value]]\n",
    "    \n",
    "    for el in [el_min, el_max]:\n",
    "\n",
    "        rp = ro*np.tan(el*u.deg)\n",
    "        if (lo < 0*u.rad) | (lo > np.pi*u.rad):\n",
    "            lp = lo + 90*u.deg\n",
    "        else:\n",
    "            lp = lo - 90*u.deg\n",
    "\n",
    "        if lp > 2*np.pi*u.rad:\n",
    "            lp = lp - 2*np.pi*u.rad\n",
    "\n",
    "        xp = rp*np.cos(lp)\n",
    "        yp = rp*np.sin(lp)\n",
    "\n",
    "        # Wolfram equations for intersection of line with circle\n",
    "        rf = 475*u.solRad # set this to a large value outside axis lims so FOV shading spans model domain \n",
    "        dx = (xp - xo)\n",
    "        dy = (yp - yo)\n",
    "        dr = np.sqrt(dx**2 + dy**2)\n",
    "        D = (xo*yp - xp*yo)\n",
    "        discrim = np.sqrt((rf*dr)**2 - D**2)\n",
    "\n",
    "        if (lo < 0*u.rad) | (lo > np.pi*u.rad) :\n",
    "            xf = (D*dy + np.sign(dy)*dx*discrim) / (dr**2)\n",
    "            yf = (-D*dx + np.abs(dy)*discrim) / (dr**2)\n",
    "        else:\n",
    "            xf = (D*dy - np.sign(dy)*dx*discrim) / (dr**2)   \n",
    "            yf = (-D*dx - np.abs(dy)*discrim) / (dr**2)\n",
    "\n",
    "        lf = np.arctan2(yf, xf)\n",
    "        fov_patch.append([lf.value, rf.value])\n",
    "\n",
    "    fov_patch = mpl.patches.Polygon(np.array(fov_patch), color='r', alpha=0.3, zorder=1)\n",
    "    return fov_patch\n",
    "\n",
    "\n",
    "def animate_observer(model, obs, tag, add_flank=False, add_fov=False):\n",
    "    \"\"\"\n",
    "    Animate the model solution, and save as an MP4.\n",
    "    :param field: String, either 'cme', or 'ambient', specifying which solution to animate.\n",
    "    :param tag: String to append to the filename of the animation.\n",
    "    \"\"\"\n",
    "    # Set the duration of the movie\n",
    "    # Scaled so a 5 day simulation with dt_scale=4 is a 10 second movie.\n",
    "    duration = model.simtime.value * (10 / 432000)\n",
    "\n",
    "    def make_frame(t):\n",
    "        \"\"\"\n",
    "        Produce the frame required by MoviePy.VideoClip.\n",
    "        :param t: time through the movie\n",
    "        \"\"\"\n",
    "        # Get the time index closest to this fraction of movie duration\n",
    "        i = np.int32((model.nt_out - 1) * t / duration)\n",
    "        fig, ax = plot_huxt_with_observer(model.time_out[i], model, obs, add_flank=add_flank, add_fov=add_fov)\n",
    "        frame = mplfig_to_npimage(fig)\n",
    "        plt.close('all')\n",
    "        return frame\n",
    "\n",
    "    cr_num = np.int32(model.cr_num.value)\n",
    "    filename = \"HUXt_CR{:03d}_{}_movie.mp4\".format(cr_num, tag)\n",
    "    filepath = os.path.join(model._figure_dir_, filename)\n",
    "    animation = mpy.VideoClip(make_frame, duration=duration)\n",
    "    animation.write_videofile(filepath, fps=24, codec='libx264')\n",
    "    return\n",
    "\n",
    "def compute_profile_difference(obs_flank, model_flank):\n",
    "    \"\"\"\n",
    "    Compute the rms difference between the observed and modelled flank elongations. \n",
    "    \"\"\"\n",
    "    # Do interp rather than join of dataframes, as it generalises out of model world. \n",
    "    elon_interp = np.interp(obs_flank['time'].values, model_flank['time'].values, model_flank['el'].values, left=np.NaN, right=np.NaN)\n",
    "    matched_model = pd.DataFrame({'time': obs_flank['time'].values, 'el': elon_interp})\n",
    "    de = (matched_model['el'] - obs_flank['el'])**2\n",
    "    n_rms_samp = np.sum(np.isfinite(de))\n",
    "    rms = np.sqrt(de.mean(skipna=True))\n",
    "    return rms, n_rms_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already exist for CR2065\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-708afe95d650>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# Perturb the CME and solve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mcme_ens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperturb_cone_cme\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcme_base\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcme_ens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mcme_ens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\research\\repos\\SIR_HUXt\\code\\HUXt.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self, cme_list, save, save_cmes, tag)\u001b[0m\n\u001b[0;32m    640\u001b[0m                                                                    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m                                                                    \u001b[0mdo_cme\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mcme_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m                                                                    self.latitude.value)\n\u001b[0m\u001b[0;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_grid_amb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv_amb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_grid_cme\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv_cme\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(20200114)\n",
    "start_time = Time('2008-01-01T00:00:00')\n",
    "model = setup_huxt(start_time, uniform_wind=True)\n",
    "\n",
    "# Initialise Earth directed CME. Coords in HEEQ, so need Earth Lat.\n",
    "ert = model.get_observer('EARTH')\n",
    "avg_ert_lat = np.mean(ert.lat.to(u.deg).value)\n",
    "cme_base = get_base_cme(v=1000, lon=0, lat=avg_ert_lat, width=35)\n",
    "\n",
    "# Perturb the base CME to get a \"pseudo-truth\", and solve\n",
    "cme_truth = perturb_cone_cme(cme_base)\n",
    "model.solve([cme_truth])\n",
    "\n",
    "cme_truth = model.cmes[0]\n",
    "observer_lon = -60*u.deg\n",
    "observer = Observer(model, observer_lon, el_min=4.0, el_max=40.0)\n",
    "true_observed_flank = observer.compute_synthetic_obs(el_spread=0.5, cadence=3, el_min=observer.el_min, el_max=observer.el_max)\n",
    "#animate_observer(model, observer, 'observer_test', add_flank=True, add_fov=True)\n",
    "    \n",
    "# Now produce ensemble run.\n",
    "n_ensembles = 20\n",
    "n_members = 50\n",
    "\n",
    "filename = \"SIR_HUXt_test.hdf5\"\n",
    "out_file = h5py.File(filename, 'w')\n",
    "\n",
    "out_file.create_dataset('n_ensembles', data=n_ensembles)\n",
    "\n",
    "cme_params = get_cme_params_for_sir(cme_base)\n",
    "out_file.create_dataset('base_cme_params', data=cme_params)\n",
    "cme_params = get_cme_params_for_sir(cme_truth)\n",
    "out_file.create_dataset('truth_cme_params', data=cme_params)\n",
    "out_file.create_dataset('true_model_flank', data=observer.model_flank.values)\n",
    "out_file.create_dataset('true_observed_flank', data=true_observed_flank.values)\n",
    "\n",
    "for i in range(n_ensembles):\n",
    "    \n",
    "    ensgrp = out_file.create_group('ensemble_{:02d}'.format(i))\n",
    "    ensgrp.create_dataset('n_members', data=n_members)\n",
    "    \n",
    "    for j in range(n_members):\n",
    "    \n",
    "        # Perturb the CME and solve\n",
    "        cme_ens = perturb_cone_cme(cme_base)\n",
    "        model.solve([cme_ens])\n",
    "        cme_ens = model.cmes[0]\n",
    "\n",
    "        ens_observer = Observer(model, observer_lon, el_min=4.0, el_max=40.0)\n",
    "\n",
    "        # Compute RMSE between ens_observer model flank and truth observations\n",
    "        profile_rms, n_samp = compute_profile_difference(true_observed_flank, ens_observer.model_flank)\n",
    "\n",
    "        # Stash this CMEs parameters, observed flank, and arrival time\n",
    "        memgrp = ensgrp.create_group('member_{:02d}'.format(j))\n",
    "        cme_params = get_cme_params_for_sir(cme_ens)\n",
    "        memgrp.create_dataset('cme_params', data=cme_params)\n",
    "        memgrp.create_dataset('model_flank', data=ens_observer.model_flank.values)\n",
    "        memgrp.create_dataset('arrival', data=cme_ens.earth_arrival_time.jd)\n",
    "        memgrp.create_dataset('profile_rms', data=profile_rms)\n",
    "        memgrp.create_dataset('n_rms_samples', data=n_samp)\n",
    "        \n",
    "    out_file.flush()\n",
    "\n",
    "out_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_arrival_dist(i, arrivals, weights, arrival_tru):\n",
    "\n",
    "    arrivals = Time(np.array(arrivals),format='jd')\n",
    "\n",
    "    arrival_tru = Time(arrival_tru, format='jd')\n",
    "    window = 5.0/24\n",
    "    dt = 1.0/24\n",
    "    bins = np.arange((arrival_tru - window).jd, (arrival_tru + window+dt).jd, dt)\n",
    "    bins = Time(bins, format='jd')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    ax.hist(arrivals.datetime, bins.datetime, density=True, color='lightgrey', label='Prior', alpha=1.0)\n",
    "    ax.hist(arrivals.datetime, bins.datetime, density=True, weights=weights, color='deepskyblue', alpha=0.5, label='Posterior')\n",
    "    ax.vlines(arrival_tru.datetime, 0,10,'r')\n",
    "\n",
    "    ax.set_xlabel('CME arrival time (day-hour)')\n",
    "    hours = mpl.dates.HourLocator(interval=4)   # every hour\n",
    "    hours_fmt = mpl.dates.DateFormatter('%d-%H')\n",
    "    # format the ticks\n",
    "    ax.xaxis.set_major_locator(hours)\n",
    "    ax.xaxis.set_major_formatter(hours_fmt)\n",
    "\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "    figname = \"arrival_hist_ensemble_{:02d}.png\".format(i)\n",
    "    fig.savefig(figname)\n",
    "    plt.close('all')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2454468.83852218 2454468.83314612 2454468.84263403 2454468.85218885\n",
      " 2454468.84477214 2454468.83711563 2454468.83639239 2454468.8445641\n",
      " 2454468.8413798  2454468.8375605  2454468.83501119 2454468.826581\n",
      " 2454468.84519123 2454468.85548864 2454468.85847644 2454468.85094247\n",
      " 2454468.84416314 2454468.83135721 2454468.8455644  2454468.8392982\n",
      " 2454468.82752657 2454468.83920889 2454468.84326878 2454468.83836525\n",
      " 2454468.84142702 2454468.84310046 2454468.8494239  2454468.84470091\n",
      " 2454468.85207925 2454468.8293577  2454468.83526597 2454468.83274438\n",
      " 2454468.83462817 2454468.84251292 2454468.84140724 2454468.84645476\n",
      " 2454468.83893983 2454468.83291845 2454468.83441399 2454468.82944362\n",
      " 2454468.83589208 2454468.84552084 2454468.85513425 2454468.83693584\n",
      " 2454468.84070317 2454468.84660943 2454468.84307534 2454468.84013807]\n",
      "[2454468.84690222 2454468.84794539 2454468.8547109  2454468.86388313\n",
      " 2454468.85913654 2454468.85221058 2454468.84849967 2454468.85426737\n",
      " 2454468.85177705 2454468.84780535 2454468.84535211 2454468.83629588\n",
      " 2454468.85693497 2454468.86431886 2454468.87049919 2454468.86191689\n",
      " 2454468.85458521 2454468.84345327 2454468.85865229 2454468.85137172\n",
      " 2454468.83869838 2454468.85055981 2454468.85603536 2454468.84830583\n",
      " 2454468.84873164 2454468.85620401 2454468.8615579  2454468.85312559\n",
      " 2454468.86569137 2454468.841547   2454468.84717829 2454468.84796214\n",
      " 2454468.84315796 2454468.8559299  2454468.8520636  2454468.85653412\n",
      " 2454468.85291323 2454468.84490527 2454468.84475114 2454468.84110393\n",
      " 2454468.8460601  2454468.85735971 2454468.86914195 2454468.84514894\n",
      " 2454468.85225838 2454468.85637559 2454468.85300993 2454468.85536734]\n"
     ]
    }
   ],
   "source": [
    "# Collect the arrival time estimates, and compute the rmse of each profile\n",
    "filename = \"SIR_HUXt_test.hdf5\"\n",
    "out_file = h5py.File(filename, 'r')\n",
    "\n",
    "arrival_tru_jd = cme_truth.earth_arrival_time.jd\n",
    "\n",
    "n_ensembles = 48 # bodge as quit early\n",
    "avg_arrival_prior = np.zeros(n_ensembles)\n",
    "avg_arrival_posterior = np.zeros(n_ensembles)\n",
    "\n",
    "for i in range(n_ensembles):\n",
    "    ensemble_key = 'ensemble_{:02d}'.format(i)\n",
    "    ensemble = out_file[ensemble_key]\n",
    "    arrivals = np.zeros(n_members)\n",
    "    profile_rmse = np.zeros(n_members)\n",
    "    for j in range(n_members):\n",
    "    \n",
    "        member_key = 'member_{:02d}'.format(j)\n",
    "        arrivals[j] = ensemble[member_key+\"/arrival\"][()]\n",
    "        profile_rmse[j] = ensemble[member_key+\"/profile_rms\"][()]\n",
    "        \n",
    "    \n",
    "    avg_arrival_prior[i] = np.average(arrivals)\n",
    "    weights = 1.0 / profile_rmse\n",
    "    weights = weights / np.sum(weights)\n",
    "    avg_arrival_posterior[i] = np.average(arrivals, weights=weights)\n",
    "    #plot_arrival_dist(i, arrivals, weights, arrival_tru_jd)\n",
    "\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the arrival time estimates, and compute the rmse of each profile\n",
    "filename = \"SIR_HUXt_test.hdf5\"\n",
    "out_file = h5py.File(filename, 'r')\n",
    "\n",
    "arrival_tru_jd = cme_truth.earth_arrival_time.jd\n",
    "\n",
    "n_ensembles = 48 # bodge as quit early\n",
    "avg_arrival_prior = np.zeros(n_ensembles)\n",
    "avg_arrival_posterior = np.zeros(n_ensembles)\n",
    "v_prior = np.zeros(n_ensembles)\n",
    "v_posterior = np.zeros(n_ensembles)\n",
    "\n",
    "for i in range(n_ensembles):\n",
    "    ensemble_key = 'ensemble_{:02d}'.format(i)\n",
    "    ensemble = out_file[ensemble_key]\n",
    "    arrivals = np.zeros(n_members)\n",
    "    profile_rmse = np.zeros(n_members)\n",
    "    cme_params = np.zeros((n_members, 6))\n",
    "    for j in range(n_members):\n",
    "    \n",
    "        member_key = 'member_{:02d}'.format(j)\n",
    "        arrivals[j] = ensemble[member_key+\"/arrival\"][()]\n",
    "        profile_rmse[j] = ensemble[member_key+\"/profile_rms\"][()]\n",
    "        cme_params[j, :] = ensemble[member_key+\"/cme_params\"][()]\n",
    "    \n",
    "    avg_arrival_prior[i] = np.average(arrivals)\n",
    "    weights = 1.0 / profile_rmse\n",
    "    weights = weights / np.sum(weights)\n",
    "    avg_arrival_posterior[i] = np.average(arrivals, weights=weights)\n",
    "    \n",
    "    v_prior[i] = np.average(cme_params[:, 4])\n",
    "    v_posterior[i] = np.average(cme_params[:, 4], axis=0, weights=weights)\n",
    "    \n",
    "\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth:942.5513668409623 km / s   Prior:999.7053023963266+/-14.452147857208866   Posterior:988.0205062801219+/-15.242377327499844\n",
      "57.60892720653977 46.10341807270051\n"
     ]
    }
   ],
   "source": [
    "err_v_pri = v_prior - cme_truth.v.value\n",
    "err_v_pos = v_posterior - cme_truth.v.value\n",
    "\n",
    "rmse_v_pri = np.sqrt(np.mean(err_v_pri**2))\n",
    "rmse_v_pos = np.sqrt(np.mean(err_v_pos**2))\n",
    "\n",
    "v_pri_avg = np.mean(v_prior)\n",
    "#v_pri_sem = 2*st.sem(v_prior)\n",
    "v_pri_sem = 2*np.std(v_prior)\n",
    "\n",
    "v_pos_avg = np.mean(v_posterior)\n",
    "#v_pos_sem = 2*st.sem(v_posterior)\n",
    "v_pos_sem = 2*np.std(v_posterior)\n",
    "\n",
    "print(\"Truth:{}   Prior:{}+/-{}   Posterior:{}+/-{}\".format(cme_truth.v, v_pri_avg, v_pri_sem, v_pos_avg, v_pos_sem))\n",
    "\n",
    "print(rmse_v_pri, rmse_v_pos)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(8,8))\n",
    "    axr = ax.ravel()\n",
    "    \n",
    "    # Longitude\n",
    "    lon = cme_params[:, 1]\n",
    "    lon = np.rad2deg(lon)\n",
    "    lon[lon > 180] -= 360\n",
    "    bins = np.arange(-10,12,2)\n",
    "    axr[0].hist(lon, bins, density=True, color='lightgrey', label='Prior', alpha=1.0)\n",
    "    axr[0].hist(lon, bins, density=True, weights=weights, color='deepskyblue', alpha=0.5, label='Posterior')\n",
    "    lon_tru = cme_truth.longitude.to(u.deg).value\n",
    "    if lon_tru > 180:\n",
    "        lon_tru -= 360\n",
    "    axr[0].vlines(lon_tru, 0, 0.1, 'r')\n",
    "    \n",
    "    # Latitude\n",
    "    lat = cme_params[:, 2]\n",
    "    lat = np.rad2deg(lat)\n",
    "    bins = np.arange(-10,12,2)\n",
    "    axr[1].hist(lat, bins, density=True, color='lightgrey', label='Prior', alpha=1.0)\n",
    "    axr[1].hist(lat, bins, density=True, weights=weights, color='deepskyblue', alpha=0.5, label='Posterior')\n",
    "    lat_tru = cme_truth.latitude.to(u.deg).value\n",
    "    axr[1].vlines(lat_tru, 0, 0.1, 'r')\n",
    "    \n",
    "    # Width\n",
    "    wid = cme_params[:, 3]\n",
    "    wid = np.rad2deg(wid)\n",
    "    bins = np.arange(30, 62, 2)\n",
    "    axr[2].hist(wid, bins, density=True, color='lightgrey', label='Prior', alpha=1.0)\n",
    "    axr[2].hist(wid, bins, density=True, weights=weights, color='deepskyblue', alpha=0.5, label='Posterior')\n",
    "    wid_tru = cme_truth.width.to(u.deg).value\n",
    "    axr[2].vlines(wid_tru, 0, 0.1, 'r')\n",
    "    \n",
    "    # Speed\n",
    "    v = cme_params[:, 4]\n",
    "    bins = np.arange(800, 1225, 25)\n",
    "    axr[3].hist(v, bins, density=True, color='lightgrey', label='Prior', alpha=1.0)\n",
    "    axr[3].hist(v, bins, density=True, weights=weights, color='deepskyblue', alpha=0.5, label='Posterior')\n",
    "    v_tru = cme_truth.v.value\n",
    "    axr[3].vlines(v_tru, 0, 0.01, 'r')\n",
    "    \n",
    "    # Thickness\n",
    "    t = (cme_params[:, 5]*u.km).to(u.solRad).value\n",
    "    bins = np.arange(3,7.5, 0.5)\n",
    "    axr[4].hist(t, bins, density=True, color='lightgrey', label='Prior', alpha=1.0)\n",
    "    axr[4].hist(t, bins, density=True, weights=weights, color='deepskyblue', alpha=0.5, label='Posterior')\n",
    "    t_tru = cme_truth.thickness.value\n",
    "    print(t_tru)\n",
    "    axr[4].vlines(t_tru, 0, 0.6, 'r')\n",
    "    \n",
    "    for a in axr:\n",
    "        a.set_yticklabels([])\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.510185951282149 2.23616169252759 1.1225422381888772\n"
     ]
    }
   ],
   "source": [
    "err_prior = (avg_arrival_prior - arrival_tru_jd)*24\n",
    "err_posterior = (avg_arrival_posterior - arrival_tru_jd)*24\n",
    "\n",
    "rmse_prior = np.sqrt(np.mean(err_prior**2))\n",
    "rmse_posterior = np.sqrt(np.mean(err_posterior**2))\n",
    "\n",
    "print(rmse_prior, rmse_posterior, rmse_prior/rmse_posterior)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
