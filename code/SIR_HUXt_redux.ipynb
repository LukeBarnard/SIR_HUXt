{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.time import Time, TimeDelta\n",
    "import astropy.units as u\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import moviepy.editor as mpy\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sunpy.coordinates.sun as sn\n",
    "import scipy.stats as st\n",
    "# Local packages\n",
    "import HUXt as H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_huxt(start_time, uniform_wind=True):\n",
    "    \"\"\"\n",
    "    Initialise HUXt with some predetermined boundary/initial conditions\n",
    "    uniform_wind is flag for setting uniform 400km/s wind.\n",
    "    :param start_time: An astropy.Time object specifying the start time of HUXt\n",
    "    :param uniform_wind: If True, set the wind to be uniform 400km/s\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    cr_num = np.fix(sn.carrington_rotation_number(start_time))\n",
    "    ert = H.Observer('EARTH', start_time)\n",
    "\n",
    "    # Set up HUXt for a 5 day simulation with homogenous inner boundary.\n",
    "    vr_in, br_in = H.Hin.get_MAS_long_profile(cr_num, ert.lat.to(u.deg))\n",
    "    if uniform_wind:\n",
    "        vr_in = np.zeros(vr_in.shape) + 400*vr_in.unit\n",
    "        \n",
    "    model = H.HUXt(v_boundary=vr_in, cr_num=cr_num, cr_lon_init=ert.lon_c, latitude=ert.lat.to(u.deg),\n",
    "                   br_boundary=br_in, lon_start=270*u.deg, lon_stop=90*u.deg, simtime=3.5*u.day, dt_scale=4)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_base_cme(v=1000, lon=0, lat=0, width=35, thickness=1):\n",
    "    \"\"\"\n",
    "    Return the base CME, which is used to establish the pseudo-truth CME and the SIR ensemble\n",
    "    :param v: CME speed in km/s\n",
    "    :param lon: CME longtiude in degrees\n",
    "    :param lat: CME latitude in degrees\n",
    "    :param width: CME width in degrees\n",
    "    :param thickness: CME thickness in solar radii\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    t_launch = (1*u.hr).to(u.s)\n",
    "    cme = H.ConeCME(t_launch=t_launch, longitude=lon*u.deg, latitude=lat*u.deg, width=width*u.deg, v=v*(u.km/u.s),\n",
    "                    thickness=thickness*u.solRad)\n",
    "    return cme\n",
    "\n",
    "\n",
    "def perturb_cone_cme(cme):\n",
    "    \"\"\"\n",
    "    Perturb a ConeCME's parameters. Used to establish the pseudo-truth CME and the initial SIR ensemble members.\n",
    "    :param cme: A ConeCME object\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    lon_spread = 10*u.deg\n",
    "    lat_spread = 10*u.deg\n",
    "    width_spread = 10*u.deg\n",
    "    v_spread = 150*(u.km/u.s)\n",
    "    thickness_spread = 1*u.solRad\n",
    "    \n",
    "    randoms = np.random.uniform(-1, 1, 5)\n",
    "    lon_new = cme.longitude + randoms[0]*lon_spread\n",
    "    lat_new = cme.latitude + randoms[1]*lat_spread\n",
    "    width_new = cme.width + randoms[2]*width_spread\n",
    "    v_new = cme.v + randoms[3]*v_spread\n",
    "    thickness_new = cme.thickness + randoms[4]*thickness_spread\n",
    "    \n",
    "    cme_perturb = H.ConeCME(t_launch=cme.t_launch,\n",
    "                            longitude=lon_new,\n",
    "                            latitude=lat_new,\n",
    "                            width=width_new,\n",
    "                            v=v_new,\n",
    "                            thickness=thickness_new)\n",
    "    return cme_perturb\n",
    "\n",
    "\n",
    "class Observer:\n",
    "    \n",
    "    @u.quantity_input(longitude=u.deg)\n",
    "    def __init__(self, model, longitude, el_min=4.0, el_max=30.0):\n",
    "        \n",
    "        ert_ephem = model.get_observer('EARTH')\n",
    "        \n",
    "        self.time = ert_ephem.time \n",
    "        self.r = ert_ephem.r\n",
    "        self.lon = ert_ephem.lon + longitude\n",
    "        self.lat = ert_ephem.lat\n",
    "        self.el_min = el_min\n",
    "        self.el_max = el_max\n",
    "        # Force longitude into 0-360 domain\n",
    "        id_over = self.lon > 360*u.deg\n",
    "        id_under = self.lon < 0*u.deg\n",
    "        if np.any(id_over):\n",
    "            self.lon[id_over] = self.lon[id_over] - 360*u.deg\n",
    "        if np.any(id_under):\n",
    "            self.lon[id_under] = self.lon[id_under] + 360*u.deg\n",
    "        \n",
    "        cme = model.cmes[0]\n",
    "        self.model_flank = self.compute_flank_profile(cme)\n",
    "        \n",
    "    def compute_flank_profile(self, cme):\n",
    "        \"\"\"\n",
    "        Compute the time elongation profile of the flank of a ConeCME in HUXt. The observer longtidue is specified\n",
    "        relative to Earth but otherwise matches Earth's coords.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cme: A ConeCME object from a completed HUXt run (i.e the ConeCME.coords dictionary has been populated).\n",
    "        Returns\n",
    "        -------\n",
    "        obs_profile: Pandas dataframe giving the coordinates of the ConeCME flank from STA's perspective, including the\n",
    "                    time, elongation, position angle, and HEEQ radius and longitude.\n",
    "        \"\"\"\n",
    "        times = Time([coord['time'] for i, coord in cme.coords.items()])\n",
    "\n",
    "        # Compute observers location using earth ephem, adding on observers longitude offset from Earth\n",
    "        # and correct for runover 2*pi\n",
    "        flank = pd.DataFrame(index=np.arange(times.size), columns=['time', 'el', 'r', 'lon'])\n",
    "        flank['time'] = times.jd\n",
    "\n",
    "        for i, coord in cme.coords.items():\n",
    "\n",
    "            if len(coord['r']) == 0:\n",
    "                flank.loc[i, ['lon', 'r', 'el']] = np.NaN\n",
    "                continue\n",
    "\n",
    "            r_obs = self.r[i]\n",
    "            x_obs = self.r[i] * np.cos(self.lat[i]) * np.cos(self.lon[i])\n",
    "            y_obs = self.r[i] * np.cos(self.lat[i]) * np.sin(self.lon[i])\n",
    "            z_obs = self.r[i] * np.sin(self.lat[i])\n",
    "\n",
    "            lon_cme = coord['lon']\n",
    "            lat_cme = coord['lat']\n",
    "            r_cme = coord['r']\n",
    "\n",
    "            x_cme = r_cme * np.cos(lat_cme) * np.cos(lon_cme)\n",
    "            y_cme = r_cme * np.cos(lat_cme) * np.sin(lon_cme)\n",
    "            z_cme = r_cme * np.sin(lat_cme)\n",
    "            #############\n",
    "            # Compute the observer CME distance, S, and elongation\n",
    "\n",
    "            x_cme_s = x_cme - x_obs\n",
    "            y_cme_s = y_cme - y_obs\n",
    "            z_cme_s = z_cme - z_obs\n",
    "            s = np.sqrt(x_cme_s**2 + y_cme_s**2 + z_cme_s**2)\n",
    "\n",
    "            numer = (r_obs**2 + s**2 - r_cme**2).value\n",
    "            denom = (2.0 * r_obs * s).value\n",
    "            e_obs = np.arccos(numer / denom)\n",
    "\n",
    "            # Find the flank coordinate and update output\n",
    "            id_obs_flank = np.argmax(e_obs)       \n",
    "            flank.loc[i, 'lon'] = lon_cme[id_obs_flank].value\n",
    "            flank.loc[i, 'r'] = r_cme[id_obs_flank].value\n",
    "            flank.loc[i, 'el'] = np.rad2deg(e_obs[id_obs_flank])\n",
    "\n",
    "        # Force values to be floats.\n",
    "        keys = ['lon', 'r', 'el']\n",
    "        flank[keys] = flank[keys].astype(np.float64)\n",
    "        return flank\n",
    "    \n",
    "    def compute_synthetic_obs(self, el_spread=0.5, cadence=5, el_min=4.0, el_max=30.0):\n",
    "        \"\"\"\n",
    "        Return synthetic observations with a specified uncertainty spread, cadence, and maximum elongation.\n",
    "        el_spread = standard deviation of random gaussian noise added to the modelled elongation.\n",
    "        cadence = The cadence with witch observations are returned, as a whole number of model time steps.\n",
    "        el_min = The minimum elongation of the observers field of view.\n",
    "        el_max = The maximum elongation of the observers field of view.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute the time-elongation profiles of the CME flanks from STA and STB\n",
    "        model_flank = self.model_flank.copy()\n",
    "\n",
    "        # Remove invalid points\n",
    "        model_flank.dropna(inplace=True)\n",
    "\n",
    "        # Add observation noise.\n",
    "        obs_flank = model_flank.loc[:, ['time', 'el']].copy()\n",
    "        obs_flank['el'] = obs_flank['el'] + el_spread*np.random.randn(obs_flank.shape[0])\n",
    "\n",
    "        # Only keep every dt_scale'th observation and reindex - dt_scale=5 corrsponds to ~2hr\n",
    "        obs_flank = obs_flank[::cadence]\n",
    "        obs_flank.set_index(np.arange(0, obs_flank.shape[0]), inplace=True)\n",
    "\n",
    "        # Only return up to el_max ~ (approx HI1 FOV is 25deg)\n",
    "        id_fov = (obs_flank['el'] >= el_min) & (obs_flank['el'] <= el_max)\n",
    "        obs_flank = obs_flank[id_fov]\n",
    "        # Reindex to start from 0, or loops misbehave.\n",
    "        obs_flank.set_index(np.arange(0, obs_flank.shape[0]), inplace=True)\n",
    "        return obs_flank\n",
    "\n",
    "\n",
    "def plot_huxt_with_observer(time, model, observer, add_flank=False, add_fov=False):\n",
    "    \"\"\"\n",
    "    Plot the HUXt solution at a specified time, and (optionally) overlay the modelled flank location and field of view\n",
    "    of a specified observer.\n",
    "    :param time: The time to plot. The closest value in model.time_out is selected.\n",
    "    :param model: A HUXt instance with the solution in.\n",
    "    :param observer: An Observer instance with the modelled flank.\n",
    "    :param add_flank: If True, add the modelled flank.\n",
    "    :param add_fov: If True, highlight the observers field of view.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    id_t = np.argmin(np.abs(model.time_out - time))\n",
    "\n",
    "    # Get plotting data\n",
    "    lon_arr, dlon, nlon = H.longitude_grid()\n",
    "    lon, rad = np.meshgrid(lon_arr.value, model.r.value)\n",
    "    mymap = mpl.cm.viridis\n",
    "    v_sub = model.v_grid_cme.value[id_t, :, :].copy()\n",
    "    # Insert into full array\n",
    "    if lon_arr.size != model.lon.size:\n",
    "        v = np.zeros((model.nr, nlon)) * np.NaN\n",
    "        if model.lon.size != 1:\n",
    "            for i, lo in enumerate(model.lon):\n",
    "                id_match = np.argwhere(lon_arr == lo)[0][0]\n",
    "                v[:, id_match] = v_sub[:, i]\n",
    "        else:\n",
    "            print('Warning: Trying to contour single radial solution will fail.')\n",
    "    else:\n",
    "        v = v_sub\n",
    "\n",
    "    # Pad out to fill the full 2pi of contouring\n",
    "    pad = lon[:, 0].reshape((lon.shape[0], 1)) + model.twopi\n",
    "    lon = np.concatenate((lon, pad), axis=1)\n",
    "    pad = rad[:, 0].reshape((rad.shape[0], 1))\n",
    "    rad = np.concatenate((rad, pad), axis=1)\n",
    "    pad = v[:, 0].reshape((v.shape[0], 1))\n",
    "    v = np.concatenate((v, pad), axis=1)\n",
    "\n",
    "    mymap.set_over('lightgrey')\n",
    "    mymap.set_under([0, 0, 0])\n",
    "    levels = np.arange(200, 800 + 10, 10)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": \"polar\"})\n",
    "    cnt = ax.contourf(lon, rad, v, levels=levels, cmap=mymap, extend='both')\n",
    "\n",
    "    # Add on CME boundaries and Observer\n",
    "    cme = model.cmes[0]\n",
    "    ax.plot(cme.coords[id_t]['lon'], cme.coords[id_t]['r'], '-', color='darkorange', linewidth=3, zorder=3)\n",
    "    ert = model.get_observer('EARTH')\n",
    "    ax.plot(ert.lon[id_t], ert.r[id_t], 'co', markersize=16, label='Earth')            \n",
    "\n",
    "    # Add on the observer\n",
    "    ax.plot(observer.lon[id_t], observer.r[id_t], 's', color='r', markersize=16, label='Observer')\n",
    "        \n",
    "    if add_flank:\n",
    "        flank_lon = observer.model_flank.loc[id_t, 'lon']\n",
    "        flank_rad = observer.model_flank.loc[id_t, 'r']\n",
    "        ax.plot(flank_lon, flank_rad, 'r.', markersize=10, zorder=4)\n",
    "        # Add observer-flank line\n",
    "        ro = observer.r[id_t]\n",
    "        lo = observer.lon[id_t]\n",
    "        ax.plot([lo.value, flank_lon], [ro.value, flank_rad], 'r--', zorder=4)\n",
    "        \n",
    "    if add_fov:\n",
    "        fov_patch = get_fov_patch(observer.r[id_t], observer.lon[id_t], observer.el_min, observer.el_max)\n",
    "        ax.add_patch(fov_patch)\n",
    "\n",
    "    ax.set_ylim(0, 240)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.patch.set_facecolor('slategrey')\n",
    "\n",
    "    fig.subplots_adjust(left=0.05, bottom=0.16, right=0.95, top=0.99)\n",
    "    # Add color bar\n",
    "    pos = ax.get_position()\n",
    "    dw = 0.005\n",
    "    dh = 0.045\n",
    "    left = pos.x0 + dw\n",
    "    bottom = pos.y0 - dh\n",
    "    wid = pos.width - 2 * dw\n",
    "    cbaxes = fig.add_axes([left, bottom, wid, 0.03])\n",
    "    cbar1 = fig.colorbar(cnt, cax=cbaxes, orientation='horizontal')\n",
    "    cbar1.set_label('Solar Wind speed (km/s)')\n",
    "    cbar1.set_ticks(np.arange(200, 810, 100))\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def get_fov_patch(ro, lo, el_min, el_max):\n",
    "    \"\"\"\n",
    "    Function to compute a matplotlib patch to higlight an observers field of view. \n",
    "    ro = radius of observer (in solRad)\n",
    "    lo = longitude of observer (in rad)\n",
    "    el_min = minimum elongation of the field of view\n",
    "    el_max = maximum elongation of the field of view\n",
    "    \"\"\"\n",
    "    xo = ro*np.cos(lo)\n",
    "    yo = ro*np.sin(lo)\n",
    "    \n",
    "    fov_patch = [[lo.value, ro.value]]\n",
    "    \n",
    "    for el in [el_min, el_max]:\n",
    "\n",
    "        rp = ro*np.tan(el*u.deg)\n",
    "        if (lo < 0*u.rad) | (lo > np.pi*u.rad):\n",
    "            lp = lo + 90*u.deg\n",
    "        else:\n",
    "            lp = lo - 90*u.deg\n",
    "\n",
    "        if lp > 2*np.pi*u.rad:\n",
    "            lp = lp - 2*np.pi*u.rad\n",
    "\n",
    "        xp = rp*np.cos(lp)\n",
    "        yp = rp*np.sin(lp)\n",
    "\n",
    "        # Wolfram equations for intersection of line with circle\n",
    "        rf = 475*u.solRad  # set this to a large value outside axis lims so FOV shading spans model domain\n",
    "        dx = (xp - xo)\n",
    "        dy = (yp - yo)\n",
    "        dr = np.sqrt(dx**2 + dy**2)\n",
    "        det = (xo*yp - xp*yo)\n",
    "        discrim = np.sqrt((rf*dr)**2 - det**2)\n",
    "\n",
    "        if (lo < 0*u.rad) | (lo > np.pi*u.rad):\n",
    "            xf = (det*dy + np.sign(dy)*dx*discrim) / (dr**2)\n",
    "            yf = (-det*dx + np.abs(dy)*discrim) / (dr**2)\n",
    "        else:\n",
    "            xf = (det*dy - np.sign(dy)*dx*discrim) / (dr**2)\n",
    "            yf = (-det*dx - np.abs(dy)*discrim) / (dr**2)\n",
    "\n",
    "        lf = np.arctan2(yf, xf)\n",
    "        fov_patch.append([lf.value, rf.value])\n",
    "\n",
    "    fov_patch = mpl.patches.Polygon(np.array(fov_patch), color='r', alpha=0.3, zorder=1)\n",
    "    return fov_patch\n",
    "\n",
    "\n",
    "def animate_observer(model, obs, tag, add_flank=False, add_fov=False):\n",
    "    \"\"\"\n",
    "    Animate the model solution, and save as an MP4.\n",
    "    :param model: A HXUt model instance with the solution in\n",
    "    :param obs: An observer instance containing the modelled flank coords\n",
    "    :param tag: String to append to filename\n",
    "    :param add_flank: If True, the modelled flank is plotted\n",
    "    :param add_fov: If True, the observers field of view is highlighted\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Set the duration of the movie\n",
    "    # Scaled so a 5 day simulation with dt_scale=4 is a 10 second movie.\n",
    "    duration = model.simtime.value * (10 / 432000)\n",
    "\n",
    "    def make_frame(t):\n",
    "        \"\"\"\n",
    "        Produce the frame required by MoviePy.VideoClip.\n",
    "        :param t: time through the movie\n",
    "        \"\"\"\n",
    "        # Get the time index closest to this fraction of movie duration\n",
    "        i = np.int32((model.nt_out - 1) * t / duration)\n",
    "        fig, ax = plot_huxt_with_observer(model.time_out[i], model, obs, add_flank=add_flank, add_fov=add_fov)\n",
    "        frame = mplfig_to_npimage(fig)\n",
    "        plt.close('all')\n",
    "        return frame\n",
    "\n",
    "    cr_num = np.int32(model.cr_num.value)\n",
    "    filename = \"HUXt_CR{:03d}_{}_movie.mp4\".format(cr_num, tag)\n",
    "    filepath = os.path.join(model._figure_dir_, filename)\n",
    "    animation = mpy.VideoClip(make_frame, duration=duration)\n",
    "    animation.write_videofile(filepath, fps=24, codec='libx264')\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_elon_profiles_at_analysis(step, model, observer, cme_truth_obs, t_obs, e_obs, ens_profiles, weights):\n",
    "    \"\"\"\n",
    "    Plot the time-elongation profiles of the truth cme, the full ensemble, and the observations.\n",
    "    :param step: Integer number for the analysis step (used in naming)\n",
    "    :param model: The HUXt model object\n",
    "    :param observer: An observer object with the modeled flank\n",
    "    :param cme_truth_obs: Pandas dataframe of the observed flank of the truth cme\n",
    "    :param t_obs: Time (in JD) at this analysis step\n",
    "    :param e_obs: Elongation (in degs) at this analysis step\n",
    "    :param ens_profiles: Pandas dataframe of the ensemble of time-elongation profiles\n",
    "    :param weights: An array of the weights of each ensemble member\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    keys = ens_profiles.keys()\n",
    "    keys = keys.drop('time')\n",
    "    time = (Time(ens_profiles['time'], format='jd') - model.time_init).value*24\n",
    "\n",
    "    ax[0].plot(time, ens_profiles[keys], '-', color='slategrey', zorder=1, label='Model Ens.')\n",
    "\n",
    "    cmap = mpl.cm.viridis\n",
    "    norm = mpl.colors.Normalize(vmin=np.nanmin(weights), vmax=np.nanmax(weights))\n",
    "    for i, w in enumerate(weights):\n",
    "        key = \"e_{:02d}\".format(i)\n",
    "        col = cmap(norm(w))\n",
    "        time = (Time(ens_profiles['time'], format='jd') - model.time_init).value*24\n",
    "        ax[1].plot(time, ens_profiles[key], '-', color=col, zorder=1, label='Model Ens.')\n",
    "\n",
    "    time = (Time(observer.model_flank['time'], format='jd') - model.time_init).value*24\n",
    "    ax[0].plot(time, observer.model_flank['el'], 'k-', zorder=2, label='Model Truth')\n",
    "\n",
    "    ax[1].plot(time, observer.model_flank['el'], 'k--', zorder=2, label='Model Truth')\n",
    "\n",
    "    time = (Time(cme_truth_obs['time'], format='jd') - model.time_init).value*24\n",
    "    ax[0].plot(time, cme_truth_obs['el'], 'r.', zorder=3, label='Synth. Obs.')\n",
    "\n",
    "    ax[1].plot(time, cme_truth_obs['el'], 'r.', zorder=3, label='Synth. Obs.')\n",
    "\n",
    "    time = (t_obs - model.time_init.jd)*24\n",
    "    ax[1].plot(time, e_obs, 'r*', markersize=10, zorder=3, label='Assimilation point')\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_xlabel('Model time (hours)')\n",
    "        a.set_ylabel('Elongation (deg)')\n",
    "        # Add legend, remove duplicate labels\n",
    "        handles, labels = a.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        a.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "    ax[1].yaxis.tick_right()\n",
    "    ax[1].yaxis.set_label_position('right')\n",
    "    ax[1].set_xlim(time - 5, time + 5)\n",
    "    ax[1].set_ylim(e_obs - 5, e_obs + 5)\n",
    "\n",
    "    fig.subplots_adjust(left=0.075, bottom=0.12, right=0.925, top=0.98, wspace=0.05)\n",
    "    fig.savefig('figx_truth_and_ensemble_profiles_with_lkhd_{:02d}.png'.format(step))\n",
    "    plt.close('all')\n",
    "    return\n",
    "\n",
    "\n",
    "def compute_resampling(speeds, lons, lats, widths, thicks, weights):\n",
    "    \"\"\"\n",
    "    Use gaussian kernel density estimation to generate new cme parameter values from the weighted distribution of\n",
    "    current values\n",
    "    :param speeds: Array of CME speeds of current ensemble members (in km/s)\n",
    "    :param lons: Array of CME longitudes of current ensemble members (in degs)\n",
    "    :param lats: Array of CME latitudes of current ensemble members (in degs)\n",
    "    :param widths: Array of CME widths of current ensemble members (in degs)\n",
    "    :param thicks: Array of CME thicknesses of current ensemble members (in solRad)\n",
    "    :param weights: Array of weights of the current ensemble members\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    n_members = speeds.size\n",
    "    \n",
    "    # Remove any bad values\n",
    "    id_good = np.isfinite(weights)\n",
    "    weights = weights[id_good]\n",
    "    speeds = speeds[id_good]\n",
    "    lons = lons[id_good]\n",
    "    lats = lats[id_good]\n",
    "    widths = widths[id_good]\n",
    "    thicks = thicks[id_good]\n",
    "\n",
    "    # Make sure longitudes are on -180:180 domain\n",
    "    lons[lons > 180] -= 360\n",
    "\n",
    "    params = {'speed': speeds,\n",
    "              'longitude': lons,\n",
    "              'latitude': lats,\n",
    "              'width': widths,\n",
    "              'thickness': thicks}\n",
    "    \n",
    "    samples = {'speed': np.zeros(n_members),\n",
    "               'longitude': np.zeros(n_members),\n",
    "               'latitude': np.zeros(n_members),\n",
    "               'width': np.zeros(n_members),\n",
    "               'thickness': np.zeros(n_members)}\n",
    "    \n",
    "    for i, (key, param) in enumerate(params.items()):\n",
    "\n",
    "        kde_pos = st.gaussian_kde(param, bw_method=0.175, weights=weights)\n",
    "\n",
    "        # Resample from posterior for new members.\n",
    "        new_sample = kde_pos.resample(size=n_members)\n",
    "        if key == 'thickness':\n",
    "            # Stop negative thickness\n",
    "            new_sample[new_sample < 0] = 0.1\n",
    "                \n",
    "        samples[key] = new_sample.squeeze()    \n",
    "            \n",
    "    # now make a list of cone cme objects using the resampled points. \n",
    "    updated_cmes = []\n",
    "    for i in range(n_members):\n",
    "        v = samples['speed'][i]*(u.km/u.s)\n",
    "        lon = samples['longitude'][i]*u.deg\n",
    "        lat = samples['latitude'][i]*u.deg\n",
    "        width = samples['width'][i]*u.deg\n",
    "        thickness = samples['thickness'][i]*u.solRad\n",
    "        t_launch = (1*u.hr).to(u.s)  # same as the base_cme function\n",
    "        conecme = H.ConeCME(t_launch=t_launch, longitude=lon, latitude=lat, width=width, v=v, thickness=thickness)\n",
    "        updated_cmes.append(conecme)\n",
    "        \n",
    "    return updated_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already exist for CR2071\n",
      "truth_00 - 11:21:32.574657\n",
      "truth_01 - 11:40:41.010488\n",
      "truth_02 - 12:00:06.998414\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(20100114)\n",
    "\n",
    "# Set up HUXt with Uniform wind. \n",
    "start_time = Time('2008-06-10T00:00:00')\n",
    "model = setup_huxt(start_time, uniform_wind=False)\n",
    "\n",
    "# Initialise Earth directed CME. Coords in HEEQ, so need Earth Lat.\n",
    "ert = model.get_observer('EARTH')\n",
    "avg_ert_lat = np.mean(ert.lat.to(u.deg).value)\n",
    "cme_base = get_base_cme(v=1000, lon=0, lat=avg_ert_lat, width=35, thickness=1.1)\n",
    "\n",
    "n_truths = 50\n",
    "n_members = 50\n",
    "observer_lon = -60*u.deg # approx L5 location\n",
    "\n",
    "out_filepath = 'SIR_HUXt_struc_multi_truths_jup.hdf5'\n",
    "out_file = h5py.File(out_filepath, 'w')\n",
    "\n",
    "for ttt in range(n_truths):\n",
    "    \n",
    "    if ttt == 3:\n",
    "        break\n",
    "            \n",
    "    truth_key = \"truth_{:02d}\".format(ttt)\n",
    "    truth_group = out_file.create_group(truth_key)\n",
    "    print(\"{} - {}\".format(truth_key, pd.datetime.now().time()))\n",
    "    \n",
    "    # Perturb the base CME to get a \"Truth\" CME, and solve\n",
    "    cme_truth = perturb_cone_cme(cme_base)\n",
    "    model.solve([cme_truth])\n",
    "    cme_truth = model.cmes[0]\n",
    "\n",
    "    # Setup an observer at ~L5.\n",
    "    observer = Observer(model, observer_lon, el_min=10.0, el_max=40.0)\n",
    "    cme_truth_obs = observer.compute_synthetic_obs(el_spread=0.01, cadence=5, el_min=observer.el_min, el_max=observer.el_max)\n",
    "\n",
    "    # Animate the truth run\n",
    "    #animate_observer(model, observer, truth_key, add_flank=True, add_fov=True)\n",
    "\n",
    "    # Save the truth CME parameters and osbervations\n",
    "    truth_group.create_dataset('arrival_true', data=cme_truth.earth_arrival_time.jd)\n",
    "    truth_group.create_dataset('v_true', data=cme_truth.v.value)\n",
    "    truth_group.create_dataset('lon_true', data=cme_truth.longitude.to(u.deg).value)\n",
    "    truth_group.create_dataset('lat_true', data=cme_truth.latitude.to(u.deg).value)\n",
    "    truth_group.create_dataset('width_true', data=cme_truth.width.to(u.deg).value)\n",
    "    truth_group.create_dataset('thickness_true', data=cme_truth.thickness.to(u.solRad).value)\n",
    "    truth_group.create_dataset('model_flank_true', data=observer.model_flank.values)\n",
    "    truth_group.create_dataset('observed_flank', data=cme_truth_obs.values)\n",
    "    truth_group.create_dataset('n_members', data=n_members)\n",
    "    truth_group.create_dataset('observer_lon', data=observer_lon.value)\n",
    "\n",
    "    # Loop through the observations.\n",
    "    FIRST_PASS = True\n",
    "    for i, row in cme_truth_obs.iterrows():\n",
    "\n",
    "        analysis_key = \"analysis_{:02d}\".format(i)\n",
    "        analysis_group = truth_group.create_group(analysis_key)\n",
    "\n",
    "        t_obs = row['time']\n",
    "        e_obs = row['el']\n",
    "\n",
    "        analysis_group.create_dataset('t_obs', data=t_obs)\n",
    "        analysis_group.create_dataset('e_obs', data=e_obs)\n",
    "\n",
    "        speeds = np.zeros(n_members)\n",
    "        arrivals = np.zeros(n_members)\n",
    "        lons = np.zeros(n_members)\n",
    "        lats = np.zeros(n_members)\n",
    "        widths = np.zeros(n_members)\n",
    "        thicks = np.zeros(n_members)\n",
    "        likelihood = np.zeros(n_members)\n",
    "\n",
    "        for j in range(n_members):\n",
    "\n",
    "            # Perturb the CME, solve, and get the observer data.\n",
    "            if FIRST_PASS:\n",
    "                cme_ens = perturb_cone_cme(cme_base)\n",
    "            else:\n",
    "                cme_ens = updated_cmes[j]\n",
    "\n",
    "            model.solve([cme_ens])\n",
    "            cme_ens = model.cmes[0]\n",
    "            ens_observer = Observer(model, observer_lon, el_min=4.0, el_max=40.0)\n",
    "\n",
    "            # Collect all the ensemble elongation profiles together. \n",
    "            if j == 0: \n",
    "                ens_profiles = ens_observer.model_flank.copy()\n",
    "                ens_profiles.drop(columns=['r', 'lon'], inplace=True)\n",
    "                ens_profiles.rename(columns={'el':'e_{:02d}'.format(j)}, inplace=True)\n",
    "            else:\n",
    "                ens_profiles['e_{:02d}'.format(j)] = ens_observer.model_flank['el'].copy()\n",
    "\n",
    "            # Compute the likelihood of the observation given the members profile\n",
    "            profile = ens_observer.model_flank.copy()\n",
    "            # Find closest time - there should be an exact match, but this is safer\n",
    "            #TODO - add check that closest value isn't too far away?\n",
    "            id_obs = np.argmin(np.abs(profile['time'].values - t_obs))\n",
    "            e_mod = profile.loc[id_obs, 'el']\n",
    "            # Use Guassian likelihood\n",
    "            likelihood[j] = st.norm.pdf(e_obs, loc=e_mod, scale=0.2)\n",
    "\n",
    "            # Save this members CME data\n",
    "            speeds[j] = cme_ens.v.value\n",
    "            lons[j] = cme_ens.longitude.to(u.deg).value\n",
    "            lats[j] = cme_ens.latitude.to(u.deg).value\n",
    "            widths[j] = cme_ens.width.to(u.deg).value\n",
    "            thicks[j] = cme_ens.thickness.to(u.solRad).value\n",
    "            arrivals[j] = cme_ens.earth_arrival_time.jd\n",
    "\n",
    "        FIRST_PASS = False\n",
    "\n",
    "        weights = likelihood / np.nansum(likelihood)\n",
    "\n",
    "        analysis_group.create_dataset('speeds', data=speeds)\n",
    "        analysis_group.create_dataset('lons', data=lons)\n",
    "        analysis_group.create_dataset('lats', data=lats)\n",
    "        analysis_group.create_dataset('widths', data=widths)\n",
    "        analysis_group.create_dataset('thicks', data=thicks)\n",
    "        analysis_group.create_dataset('arrivals', data=arrivals)\n",
    "        analysis_group.create_dataset('likelihood', data=likelihood)\n",
    "        analysis_group.create_dataset('weights', data=weights)\n",
    "        analysis_group.create_dataset('ens_profiles', data=ens_profiles)\n",
    "        keys = ens_profiles.columns.to_list()\n",
    "        col_names = \"    \".join(keys)\n",
    "        analysis_group.create_dataset('ens_profiles_keys', data=col_names)\n",
    "\n",
    "        out_file.flush()\n",
    "\n",
    "        # Get resampled CMEs for next iteration\n",
    "        updated_cmes = compute_resampling(speeds, lons, lats, widths, thicks, weights)\n",
    "\n",
    "        if i == 8:\n",
    "            break\n",
    "        \n",
    "out_file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************\n",
      "SIR_HUXt_uniform_multi_truths.hdf5\n",
      "!!!!!\n",
      "truth_00\n",
      "!!!!!\n",
      "************************\n",
      "analysis_00\n",
      "ESS: 30.24\n",
      "Arrival - True: 12:00 Prior: 14:24 Posterior: 14:34\n",
      "Arrival Err - Prior: 2.4001140743494034 Posterior: 2.56285834684968\n",
      "Speed - True: 937.42 Prior: 995.14 Posterior: 971.12\n",
      "************************\n",
      "analysis_08\n",
      "ESS: 33.99\n",
      "Arrival - True: 12:00 Prior: 11:59 Posterior: 11:41\n",
      "Arrival Err - Prior: -0.01195647194981575 Posterior: -0.31750763207673893\n",
      "Speed - True: 937.42 Prior: 924.35 Posterior: 929.72\n",
      "!!!!!\n",
      "truth_01\n",
      "!!!!!\n",
      "************************\n",
      "analysis_00\n",
      "ESS: 25.19\n",
      "Arrival - True: 14:31 Prior: 14:13 Posterior: 13:54\n",
      "Arrival Err - Prior: -0.2985466383397579 Posterior: -0.6190434359014034\n",
      "Speed - True: 1138.77 Prior: 998.26 Posterior: 1025.50\n",
      "************************\n",
      "analysis_08\n",
      "ESS: 33.57\n",
      "Arrival - True: 14:31 Prior: 14:06 Posterior: 14:09\n",
      "Arrival Err - Prior: -0.42138728499412537 Posterior: -0.36967067420482635\n",
      "Speed - True: 1138.77 Prior: 1048.62 Posterior: 1051.55\n",
      "!!!!!\n",
      "truth_02\n",
      "!!!!!\n",
      "************************\n",
      "analysis_00\n",
      "ESS: 30.57\n",
      "Arrival - True: 12:34 Prior: 14:33 Posterior: 14:43\n",
      "Arrival Err - Prior: 1.9801038354635239 Posterior: 2.150969859212637\n",
      "Speed - True: 963.45 Prior: 998.25 Posterior: 977.09\n",
      "************************\n",
      "analysis_08\n",
      "ESS: 4.55\n",
      "Arrival - True: 12:34 Prior: 14:02 Posterior: 12:57\n",
      "Arrival Err - Prior: 1.4660414680838585 Posterior: 0.3806968107819557\n",
      "Speed - True: 963.45 Prior: 1031.21 Posterior: 1030.40\n",
      "\n",
      "**********************\n",
      "SIR_HUXt_struc_multi_truths_jup.hdf5\n",
      "!!!!!\n",
      "truth_00\n",
      "!!!!!\n",
      "************************\n",
      "analysis_00\n",
      "ESS: 26.25\n",
      "Arrival - True: 05:12 Prior: 09:14 Posterior: 09:02\n",
      "Arrival Err - Prior: 4.023732136934996 Posterior: 3.832939837127924\n",
      "Speed - True: 937.42 Prior: 995.14 Posterior: 984.94\n",
      "************************\n",
      "analysis_08\n",
      "ESS: 35.25\n",
      "Arrival - True: 05:12 Prior: 07:49 Posterior: 07:37\n",
      "Arrival Err - Prior: 2.6069424971938133 Posterior: 2.4156582579016685\n",
      "Speed - True: 937.42 Prior: 916.21 Posterior: 922.74\n",
      "!!!!!\n",
      "truth_01\n",
      "!!!!!\n",
      "************************\n",
      "analysis_00\n",
      "ESS: 15.47\n",
      "Arrival - True: 11:03 Prior: 09:24 Posterior: 08:29\n",
      "Arrival Err - Prior: -1.6466411165893078 Posterior: -2.579026009887457\n",
      "Speed - True: 1138.77 Prior: 998.26 Posterior: 1026.36\n",
      "************************\n",
      "analysis_08\n",
      "ESS: 37.35\n",
      "Arrival - True: 11:03 Prior: 11:03 Posterior: 11:03\n",
      "Arrival Err - Prior: -0.006162699311971664 Posterior: -0.009117353707551956\n",
      "Speed - True: 1138.77 Prior: 986.94 Posterior: 991.49\n",
      "!!!!!\n",
      "truth_02\n",
      "!!!!!\n",
      "************************\n",
      "analysis_00\n",
      "ESS: 24.39\n",
      "Arrival - True: 06:10 Prior: 09:04 Posterior: 09:13\n",
      "Arrival Err - Prior: 2.892715059220791 Posterior: 3.041774947196245\n",
      "Speed - True: 963.45 Prior: 998.25 Posterior: 1005.60\n",
      "************************\n",
      "analysis_08\n",
      "ESS: 26.17\n",
      "Arrival - True: 06:10 Prior: 07:28 Posterior: 07:35\n",
      "Arrival Err - Prior: 1.2954331375658512 Posterior: 1.4189667105674744\n",
      "Speed - True: 963.45 Prior: 898.11 Posterior: 865.02\n"
     ]
    }
   ],
   "source": [
    "for out_filepath in ['SIR_HUXt_uniform_multi_truths.hdf5', 'SIR_HUXt_struc_multi_truths_jup.hdf5']:\n",
    "    print(\"\")\n",
    "    print(\"**********************\")\n",
    "    print(out_filepath)\n",
    "    \n",
    "    out_file = h5py.File(out_filepath, 'r')\n",
    "\n",
    "    for ttt in range(3):\n",
    "        t_key = \"truth_{:02d}\".format(ttt)\n",
    "        print(\"!!!!!\")\n",
    "        print(t_key)\n",
    "        print(\"!!!!!\")\n",
    "        truth_group = out_file[t_key]\n",
    "        arrival_true = truth_group['arrival_true'][()]\n",
    "\n",
    "        arr_true = Time(arrival_true, format='jd')\n",
    "        v_true = truth_group['v_true'][()]\n",
    "\n",
    "        keys = truth_group.keys()\n",
    "        analysis_keys = [k for k in keys if k.split(\"_\")[0]=='analysis']\n",
    "        for key in analysis_keys:\n",
    "            \n",
    "            if key not in ['analysis_00', 'analysis_08']:\n",
    "                continue\n",
    "\n",
    "            analysis = truth_group[key]\n",
    "\n",
    "            weights = analysis['weights'][()]\n",
    "            speeds = analysis['speeds'][()]\n",
    "            arrivals = analysis['arrivals'][()]\n",
    "\n",
    "            id_good = np.isfinite(weights)\n",
    "            if not np.all(id_good):\n",
    "                \"{} of {} members valid\".format(np.sum(id_good), id_good.size)\n",
    "\n",
    "            weights = weights[id_good]\n",
    "            speeds = speeds[id_good]\n",
    "            arrivals = arrivals[id_good]\n",
    "\n",
    "            ess = 1.0 / np.sum(weights**2)\n",
    "            print(\"************************\")\n",
    "            print(key)\n",
    "            print(\"ESS: {:3.2f}\".format(ess))    \n",
    "            arr_pri = Time(np.average(arrivals), format='jd')\n",
    "            arr_pos = Time(np.average(arrivals, weights=weights), format='jd')\n",
    "            print(\"Arrival - True: {} Prior: {} Posterior: {}\".format(arr_true.strftime(\"%H:%M\"), arr_pri.strftime(\"%H:%M\"), arr_pos.strftime(\"%H:%M\")))\n",
    "            err_pri = 24*(arr_pri - arr_true).jd\n",
    "            err_pos = 24*(arr_pos - arr_true).jd\n",
    "            print(\"Arrival Err - Prior: {} Posterior: {}\".format(err_pri, err_pos))\n",
    "\n",
    "            pri = np.average(speeds)\n",
    "            pos = np.average(speeds, weights=weights)\n",
    "            print(\"Speed - True: {:3.2f} Prior: {:3.2f} Posterior: {:3.2f}\".format(v_true, pri, pos))\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for out_filepath in ['SIR_HUXt_uniform_multi_truths.hdf5', 'SIR_HUXt_uniform_multi_truths_jup.hdf5', 'SIR_HUXt_uniform_multi_truths_script.hdf5']:\n",
    "    print(\"\")\n",
    "    print(\"**********************\")\n",
    "    print(out_filepath)\n",
    "    \n",
    "    out_file = h5py.File(out_filepath, 'r')\n",
    "\n",
    "    t_key = \"truth_00\"\n",
    "    truth_group = out_file[t_key]\n",
    "    arrival_true = truth_group['arrival_true'][()]\n",
    "\n",
    "    arr_true = Time(arrival_true, format='jd')\n",
    "    v_true = truth_group['v_true'][()]\n",
    "\n",
    "    keys = truth_group.keys()\n",
    "    analysis_keys = [k for k in keys if k.split(\"_\")[0]=='analysis']\n",
    "    for key in analysis_keys:\n",
    "\n",
    "        analysis = truth_group[key]\n",
    "\n",
    "        weights = analysis['weights'][()]\n",
    "        speeds = analysis['speeds'][()]\n",
    "        arrivals = analysis['arrivals'][()]\n",
    "\n",
    "        id_good = np.isfinite(weights)\n",
    "        if not np.all(id_good):\n",
    "            \"{} of {} members valid\".format(np.sum(id_good), id_good.size)\n",
    "\n",
    "        weights = weights[id_good]\n",
    "        speeds = speeds[id_good]\n",
    "        arrivals = arrivals[id_good]\n",
    "\n",
    "        ess = 1.0 / np.sum(weights**2)\n",
    "        print(\"************************\")\n",
    "        print(key)\n",
    "        print(\"ESS: {:3.2f}\".format(ess))    \n",
    "        arr_pri = Time(np.average(arrivals), format='jd')\n",
    "        arr_pos = Time(np.average(arrivals, weights=weights), format='jd')\n",
    "        print(\"Arrival - True: {} Prior: {} Posterior: {}\".format(arr_true.strftime(\"%H:%M\"), arr_pri.strftime(\"%H:%M\"), arr_pos.strftime(\"%H:%M\")))\n",
    "        err_pri = 24*(arr_pri - arr_true).jd\n",
    "        err_pos = 24*(arr_pos - arr_true).jd\n",
    "        print(\"Arrival Err - Prior: {} Posterior: {}\".format(err_pri, err_pos))\n",
    "\n",
    "        pri = np.average(speeds)\n",
    "        pos = np.average(speeds, weights=weights)\n",
    "        print(\"Speed - True: {:3.2f} Prior: {:3.2f} Posterior: {:3.2f}\".format(v_true, pri, pos))\n",
    "\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "out_filepath = 'SIR_HUXt_uniform_multi_truths.hdf5'\n",
    "out_file = h5py.File(out_filepath, 'r')\n",
    "\n",
    "truth_keys = out_file.keys()\n",
    "for t_key in truth_keys:\n",
    "    print(\"\")\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "    truth_group = out_file[t_key]\n",
    "    arrival_true = cme_truth.earth_arrival_time.jd\n",
    "\n",
    "    arr_true = Time(arrival_true, format='jd')\n",
    "    v_true = truth_group['v_true'][()]\n",
    "\n",
    "    keys = truth_group.keys()\n",
    "        \n",
    "    prior_key = \"analysis_00\"\n",
    "    analysis_prior = truth_group[prior_key]\n",
    "    weights = analysis_prior['weights'][()]\n",
    "    speeds = analysis_prior['speeds'][()]\n",
    "    arrivals = analysis_prior['arrivals'][()]\n",
    "    arr_pri_avg = np.average(arrivals)\n",
    "    speed_pri_avg = np.average(speeds)\n",
    "    \n",
    "    posterior_key = \"analysis_08\"\n",
    "    analysis_posterior = truth_group[posterior_key]\n",
    "    weights = analysis_posterior['weights'][()]\n",
    "    speeds = analysis_posterior['speeds'][()]\n",
    "    arrivals = analysis_posterior['arrivals'][()]\n",
    "    id_good = np.isfinite(weights)\n",
    "    weights = weights[id_good]\n",
    "    speeds = speeds[id_good]\n",
    "    arrivals = arrivals[id_good]\n",
    "    arr_pos_avg = np.average(arrivals, weights=weights)\n",
    "    speed_pos_avg = np.average(speeds, weights=weights)\n",
    "    \n",
    "    ess = 1.0 / np.sum(weights**2)\n",
    "    print(\"ESS: {:3.2f}\".format(ess))    \n",
    "    arr_pri = Time(arr_pri_avg, format='jd')\n",
    "    arr_pos = Time(arr_pos_avg, format='jd')\n",
    "    err_pri = 24*(arr_pri - arr_true).jd\n",
    "    err_pos = 24*(arr_pos - arr_true).jd\n",
    "    print(\"Arrival - True: {} Prior: {} Posterior: {}\".format(arr_true.strftime(\"%H:%M\"), arr_pri.strftime(\"%H:%M\"), arr_pos.strftime(\"%H:%M\")))\n",
    "    print(\"Arrival Err - Prior: {} Posterior: {} Ratio: {}\".format(err_pri, err_pos, err_pri/err_pos))\n",
    "    \n",
    "    err_pri = speed_pri_avg - v_true\n",
    "    err_pos = speed_pos_avg - v_true    \n",
    "    print(\"Speed - True: {:3.2f} Prior: {:3.2f} Posterior: {:3.2f}\".format(v_true, speed_pri_avg, speed_pos_avg))\n",
    "    print(\"Speed Err - Prior: {:3.2f} Posterior: {:3.2f} Ratio: {:3.2f}\".format(err_pri, err_pos, err_pri/err_pos))\n",
    "    \n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "out_filepath = 'SIR_HUXt_uniform_multi_truths.hdf5'\n",
    "out_file = h5py.File(out_filepath, 'r')\n",
    "\n",
    "truth_keys = out_file.keys()\n",
    "for t_key in truth_keys:\n",
    "    \n",
    "    if t_key == 'truth_13':\n",
    "        break\n",
    "        \n",
    "    truth_group = out_file[t_key]\n",
    "    arrival_true = truth_group['arrival_true'][()]\n",
    "    v_true = truth_group['v_true'][()]\n",
    "    lon_true = truth_group['lon_true'][()]\n",
    "    lat_true = truth_group['lat_true'][()]\n",
    "    width_true = truth_group['width_true'][()]\n",
    "    thickness_true = truth_group['thickness_true'][()]\n",
    "    \n",
    "    if lon_true > 180:\n",
    "        lon_true -= 360\n",
    "    \n",
    "    bin_dict = {'lons':np.arange(-15, 15, 0.1),\n",
    "           'lats':np.arange(-15, 15, 0.1),\n",
    "           'widths':np.arange(20, 50, 0.1),\n",
    "           'thicks':np.arange(0, 4, 0.01),\n",
    "           'speeds':np.arange(800, 1200, 1),\n",
    "           'arrivals':np.arange(arrival_true - 8.0/24, arrival_true + 8.1/24, 0.1/24)}\n",
    "\n",
    "    wid = 15\n",
    "    hei = 2*wid/3\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(wid, hei))\n",
    "    axr = ax.ravel()\n",
    "    \n",
    "    for key, label in zip(['analysis_00', 'analysis_08'], ['prior', 'posterior']):\n",
    "        \n",
    "        analysis = truth_group[key]\n",
    "        \n",
    "        for i, param_key in enumerate(['lons', 'lats', 'widths', 'thicks', 'speeds', 'arrivals']):\n",
    "            \n",
    "            weights = analysis['weights'][()]\n",
    "            param = analysis[param_key][()]\n",
    "            \n",
    "            if param_key == 'lons':\n",
    "                param[param > 180.0] -= 360                \n",
    "            \n",
    "            if label=='prior':\n",
    "                kde = st.gaussian_kde(param, bw_method=0.225)\n",
    "                color = 'slategrey'\n",
    "                axr[i].vlines(param, 0.05, 0.075, color=color)\n",
    "            elif label == 'posterior':\n",
    "                kde = st.gaussian_kde(param, bw_method=0.225, weights=weights)\n",
    "                color = 'r'\n",
    "                axr[i].vlines(param, 0.1, 0.125, color=color)\n",
    "                \n",
    "            bins = bin_dict[param_key]\n",
    "            pdf = kde.pdf(bins)\n",
    "            pdf = pdf/pdf.max()\n",
    "            axr[i].plot(bins, pdf, '-', color=color, label=label)\n",
    "            \n",
    "            \n",
    "            \n",
    "    for a, truth in zip(axr, [lon_true, lat_true, width_true, thickness_true, v_true, arrival_true]):        \n",
    "        a.vlines(truth, 0, 1, 'k', linestyles=['--'], label='True value')\n",
    "    \n",
    "    for a, label in zip(ax[0,:], ['Longitude', 'Latitude', 'Width']):\n",
    "        a.xaxis.tick_top()\n",
    "        a.set_xlabel(label)\n",
    "        a.xaxis.set_label_position('top') \n",
    "        \n",
    "    for a, label in zip(ax[1,:], ['Thickness', 'Speed', 'Arrival']):\n",
    "        a.set_xlabel(label)\n",
    "                        \n",
    "    for a in axr:\n",
    "        a.set_yticklabels([])\n",
    "        \n",
    "    axr[0].legend()\n",
    "        \n",
    "    fig.subplots_adjust(left=0.05, bottom=0.1, right=0.95, top=0.9, wspace=0.02, hspace=0.02)\n",
    "    fig.savefig(t_key+'_analysis_test.png')\n",
    "    #plt.close('all')\n",
    "    \n",
    "out_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "out_filepath = 'SIR_HUXt_uniform.hdf5'\n",
    "out_file = h5py.File(out_filepath, 'r')\n",
    "\n",
    "truth_group = out_file['truth_00']\n",
    "arrival_true = cme_truth.earth_arrival_time.jd\n",
    "\n",
    "arr_true = Time(arrival_true, format='jd')\n",
    "v_true = truth_group['v_true'][()]\n",
    "\n",
    "keys = truth_group.keys()\n",
    "analysis_keys = [k for k in keys if k.split(\"_\")[0]=='analysis']\n",
    "for key in analysis_keys:\n",
    "\n",
    "    analysis = truth_group[key]\n",
    "    \n",
    "    weights = analysis['weights'][()]\n",
    "    speeds = analysis['speeds'][()]\n",
    "    arrivals = analysis['arrivals'][()]\n",
    "    \n",
    "    id_good = np.isfinite(weights)\n",
    "    if not np.all(id_good):\n",
    "        \"{} of {} members valid\".format(np.sum(id_good), id_good.size)\n",
    "        \n",
    "    weights = weights[id_good]\n",
    "    speeds = speeds[id_good]\n",
    "    arrivals = arrivals[id_good]\n",
    "    \n",
    "    ess = 1.0 / np.sum(weights**2)\n",
    "    print(\"************************\")\n",
    "    print(key)\n",
    "    print(\"ESS: {:3.2f}\".format(ess))    \n",
    "    arr_pri = Time(np.average(arrivals), format='jd')\n",
    "    arr_pos = Time(np.average(arrivals, weights=weights), format='jd')\n",
    "    print(\"Arrival - True: {} Prior: {} Posterior: {}\".format(arr_true.strftime(\"%H:%M\"), arr_pri.strftime(\"%H:%M\"), arr_pos.strftime(\"%H:%M\")))\n",
    "    err_pri = 24*(arr_pri - arr_true).jd\n",
    "    err_pos = 24*(arr_pos - arr_true).jd\n",
    "    print(\"Arrival Err - Prior: {} Posterior: {}\".format(err_pri, err_pos))\n",
    "    \n",
    "    pri = np.average(speeds)\n",
    "    pos = np.average(speeds, weights=weights)\n",
    "    print(\"Speed - True: {:3.2f} Prior: {:3.2f} Posterior: {:3.2f}\".format(v_true, pri, pos))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
